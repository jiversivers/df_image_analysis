{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Database Cleaning\n",
    "My _dbs_ are trashed. I've got 5 different database files for one project and two of them are single tables. We are going to create a single databse and merge all the data into one database, 'hsdfm_validation_data.db'. Before doing that, though, we need to get the _phantoms2_backup_ db cleaned up, beacause it alone is something of a mess.\n",
    "\n",
    "## Phantoms Data\n",
    "This _db_ was originally created under the naive paradigm of creating one table per DO measure. Since, I migrated the tables that were there at time ito tables into a single database `phantoms2.db`. `phantoms2_backup.db` should contain all the data as `phantoms2.db` plus some newer stuff. There is also some data created on seperate days in the same table of this database. Ideally, data from the first day all gets reaggregated and placed in a table 'do_testing' while data from the second day (02/07/2025) all gets aggregated into a database 'phantom_imaging_do'. In both tables, every row should have the raw data that's in the database already and a row labelling what it was measuring (which will be encoded colloquially in the table name). This labelling row should act as a foreign key to a 'master_phantoms' table that lists the makeup of each phantom. This should all be migrated into the new master study databse, 'hsdfm_validation_data.db'.\n",
    " \n",
    "Adding to the confusion, `phantoms.db` is data from a two days prior (02/05/2025); a day of testing the probe (not imaging). It can probably be trashed, but for safety, we should add it to the 'do_testing' data table.\n",
    "\n",
    "`phantoms2.db` was created from `phantoms2_backup.db` following this premise:\n",
    "\n",
    "### Original phantom migration\n",
    "We are going to refactor the tables so all the data is in one table and all the metadata (about what was recorded) is in another table. This way the names of the tables won't be such a mess and we can process things easier through SQL logic.\n",
    "\n",
    "As it currently is we have multiple data tables that look like this:\n",
    "\n",
    "**<name=water_yeast_25uL_of_250mg_mL_yeast>**\n",
    "\n",
    "| id | time | time_from_start | dissolved_oxygen | nanoamperes | temperature |\n",
    "|:---|:-----|:----------------|:----------------|:------------|:------------|\n",
    "| 1 | datetime | 00:01 | 8.80 | 50.0 | 20.0 |\n",
    "|...|...|...|...|...|...|\n",
    "\n",
    "We want to modify the database to have two tables. One that holds all the descriptive information of the study, like this:\n",
    "\n",
    "**<name=dissolved_oxygen_study_table>**\n",
    "\n",
    "| id | start_time | sample_name | solvent | hemoglobin_concentration_mg_mL | microsphere_concentration_uL_mL | yeast_stock_added_uL_mL | yeast_concentration_mg_mL |\n",
    "|:---|:-----------|:------------|:--------|:-------------------------------|:--------------------------------|:-------------------------|:--------------------------|\n",
    "| 1 | datetime | phantom1 | water | 1 | 0.5 | 0 | 0 |\n",
    "| 2 | datetime | phantom2 | water | 1 | 0.5 | 100 | 250 |\n",
    "|...|...|...|...|...|...|...|...|\n",
    "\n",
    "And a second table that holds all the data from each sample and the reference to sample data like this:\n",
    "\n",
    "**<name=dissolved_oxygen_records>**\n",
    "\n",
    "| id | sample_name | sample_id | time | dissolved_oxygen | nanoamperes | temperature |\n",
    "|:---|:------------|:----------|:-----|:-----------------|:------------|:------------|\n",
    "| 1 | phantom1 | 1 | datetime | 8.00 | 50.00 | 20.0 |\n",
    "| 2 | phantom1 | 1 | datetime | 7.99 | 49.97 | 20.2 |\n",
    "|...|...|...|...|...|...|...|\n",
    "| 100 | phantom2 | 2 | datetime | 8.30 | 51.2 | 19.7 |\n",
    "| 101 | phantom2 | 2 | datetime | 8.27 | 50.9 | 19.9 |\n",
    "|...|...|...|...|...|...|...|\n",
    "\n",
    "Where the sample_name and sample_id columns for a foreign key pair that uniquely identifies a study row in the first table.\n",
    "\n",
    "To do migrate the current tables to this format, we will iterate through each table, prompt input for the metadata fields, and then add all the data and metadat to new tables. Then we can confirm correct migration before dropping all the old tables.\n"
   ],
   "id": "6f9c077f24aa687c"
  },
  {
   "cell_type": "code",
   "id": "8ee4c29f980cc848",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-11T22:25:33.398591Z",
     "start_time": "2025-02-11T22:25:33.395655Z"
    }
   },
   "source": [
    "import sqlite3\n",
    "import struct\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, simpledialog"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T22:33:15.690630Z",
     "start_time": "2025-02-11T22:33:15.684761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_metadata_from_user(table_name):\n",
    "    \"\"\"Prompt user for metadata fields in a single GUI window, indicating which table/sample is being processed.\"\"\"\n",
    "    root = tk.Toplevel()  # Use Toplevel to ensure it's not the main loop\n",
    "    root.title(f\"Enter Metadata for {table_name}\")\n",
    "    \n",
    "    tk.Label(root, text=f\"Entering metadata for table: {table_name}\", font=(\"Arial\", 12, \"bold\")).grid(row=0, columnspan=2, pady=5)\n",
    "    \n",
    "    labels = [\n",
    "        \"Sample Name\", \"Solvent\", \"Hemoglobin Concentration (mg/mL)\",\n",
    "        \"Microsphere Concentration (uL/mL)\", \"Yeast Stock Added (uL/mL)\", \"Yeast Concentration (mg/mL)\"\n",
    "    ]\n",
    "    entries = []\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        tk.Label(root, text=label).grid(row=i+1, column=0)\n",
    "        entry = tk.Entry(root)\n",
    "        entry.grid(row=i+1, column=1)\n",
    "        entries.append(entry)\n",
    "    \n",
    "    metadata = {}\n",
    "\n",
    "    def submit():\n",
    "        \"\"\"Collect metadata and close the window.\"\"\"\n",
    "        metadata.update({\n",
    "            \"sample_name\": entries[0].get(),\n",
    "            \"solvent\": entries[1].get(),\n",
    "            \"hemoglobin_concentration_mg_mL\": float(entries[2].get() or 0),\n",
    "            \"microsphere_concentration_uL_mL\": float(entries[3].get() or 0),\n",
    "            \"yeast_stock_added_uL_mL\": float(entries[4].get() or 0),\n",
    "            \"yeast_concentration_mg_mL\": float(entries[5].get() or 0),\n",
    "        })\n",
    "        root.destroy()\n",
    "    \n",
    "    tk.Button(root, text=\"Submit\", command=submit).grid(row=len(labels)+1, columnspan=2)\n",
    "    \n",
    "    root.wait_window()  # Wait for the window to close before proceeding\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def migrate_database(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create new tables if they don't exist\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS dissolved_oxygen_study_table (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            start_time TEXT DEFAULT CURRENT_TIMESTAMP,\n",
    "            sample_name TEXT,\n",
    "            solvent TEXT,\n",
    "            hemoglobin_concentration_mg_mL REAL,\n",
    "            microsphere_concentration_uL_mL REAL,\n",
    "            yeast_stock_added_uL_mL REAL,\n",
    "            yeast_concentration_mg_mL REAL\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS dissolved_oxygen_records (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            sample_name TEXT,\n",
    "            sample_id INTEGER,\n",
    "            time TEXT,\n",
    "            dissolved_oxygen REAL,\n",
    "            nanoamperes REAL,\n",
    "            temperature REAL,\n",
    "            FOREIGN KEY(sample_id) REFERENCES phantom_study_metadata(id)\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    \n",
    "    # Get list of old tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    tables = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "    for table in tables:\n",
    "        if table in ('dissolved_oxygen_study_table', 'dissolved_oxygen_records', 'henry_constants_calculated') or 'sqlite' in table:\n",
    "            continue  # Skip new tables\n",
    "        \n",
    "        # Extract metadata from user\n",
    "        metadata = get_metadata_from_user(table)\n",
    "        # cursor.execute('''\n",
    "        #     INSERT INTO phantom_study_metadata \n",
    "        #     (sample_name, solvent, hemoglobin_concentration_mg_mL, microsphere_concentration_uL_mL, \n",
    "        #     yeast_stock_added_uL_mL, yeast_concentration_mg_mL) \n",
    "        #     VALUES (?, ?, ?, ?, ?, ?)\n",
    "        # ''', (metadata[\"sample_name\"], metadata[\"solvent\"], metadata[\"hemoglobin_concentration_mg_mL\"],\n",
    "        #       metadata[\"microsphere_concentration_uL_mL\"], metadata[\"yeast_stock_added_uL_mL\"],\n",
    "        #       metadata[\"yeast_concentration_mg_mL\"]))\n",
    "        # \n",
    "        # sample_id = cursor.lastrowid  # Get inserted row ID\n",
    "        \n",
    "        # Copy data into dissolved_oxygen_records\n",
    "        cursor.execute(f\"SELECT id, time, dissolved_oxygen, nanoamperes, temperature FROM {table}\")\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        for row in rows:\n",
    "            _, time, dissolved_oxygen, nanoamperes, temperature = row\n",
    "            cursor.execute('''\n",
    "                INSERT INTO dissolved_oxygen_records \n",
    "                (sample_name, time, dissolved_oxygen, nanoamperes, temperature) \n",
    "                VALUES (?, ?, ?, ?, ?)\n",
    "            ''', (metadata[\"sample_name\"], time, dissolved_oxygen, nanoamperes, temperature))\n",
    "        \n",
    "        conn.commit()\n",
    "        print(f\"Migrated {len(rows)} records from {table}.\")\n",
    "    \n",
    "    # Confirm and drop old tables\n",
    "    confirm = simpledialog.askstring(\"Confirmation\", \"Do you want to drop the old tables? (yes/no):\")\n",
    "    if confirm and confirm.lower() == \"yes\":\n",
    "        for table in tables:\n",
    "            if table not in ('dissolved_oxygen_study_table', 'dissolved_oxygen_records'):\n",
    "                cursor.execute(f\"DROP TABLE {table}\")\n",
    "                print(f\"Dropped table {table}.\")\n",
    "        conn.commit()\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"Database migration complete.\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### For phantoms2_backup.db",
   "id": "7f39860810bfabc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T20:43:52.563400Z",
     "start_time": "2025-02-11T20:37:16.861636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the migration\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "db_path = filedialog.askopenfilename(title=\"Select SQLite Database\", filetypes=[(\"SQLite Database\", \"*.sqlite;*.db\")])\n",
    "if db_path:\n",
    "    migrate_database(db_path)"
   ],
   "id": "6b9dc9bb0e0c0c74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migrated 1604 records from water_henry.\n",
      "Migrated 4200 records from water_yeast_25ul_of_250mg_mL_yeast.\n",
      "Migrated 2200 records from water_yeast_100ul_of_250mg_mL_yeast.\n",
      "Migrated 125 records from phantom13_14_henry.\n",
      "Migrated 791 records from phantom12.\n",
      "Migrated 3505 records from phantom9.\n",
      "Migrated 122 records from phantom6_henry.\n",
      "Migrated 631 records from phantom3_henry.\n",
      "Migrated 121 records from water_for_phantom_cal.\n",
      "Migrated 1002 records from phantom13.\n",
      "Migrated 3215 records from phantom14.\n",
      "Migrated 3263 records from phantom6.\n",
      "Migrated 2628 records from phantom3.\n",
      "Database migration complete.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### For phantoms.db",
   "id": "6098b07c20c818ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T22:34:34.390940Z",
     "start_time": "2025-02-11T22:33:17.921580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the migration\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "db_path = filedialog.askopenfilename(title=\"Select SQLite Database\", filetypes=[(\"SQLite Database\", \"*.sqlite;*.db\")])\n",
    "if db_path:\n",
    "    migrate_database(db_path)"
   ],
   "id": "8c4cb6bc9d37a502",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migrated 129 records from water_henry_constant.\n",
      "Migrated 463 records from phantom_water_cold.\n",
      "Migrated 763 records from phantom13_14.\n",
      "Migrated 229 records from phantom12.\n",
      "Migrated 191 records from phantom9.\n",
      "Migrated 235 records from phantom6.\n",
      "Migrated 357 records from phantom3.\n",
      "Migrated 625 records from water_w_yeast_1667ul_mL_at_2_min.\n",
      "Dropped table water_henry_constant.\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "table sqlite_sequence may not be dropped",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m db_path \u001B[38;5;241m=\u001B[39m filedialog\u001B[38;5;241m.\u001B[39maskopenfilename(title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSelect SQLite Database\u001B[39m\u001B[38;5;124m\"\u001B[39m, filetypes\u001B[38;5;241m=\u001B[39m[(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSQLite Database\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*.sqlite;*.db\u001B[39m\u001B[38;5;124m\"\u001B[39m)])\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m db_path:\n\u001B[1;32m----> 6\u001B[0m     \u001B[43mmigrate_database\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdb_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[14], line 113\u001B[0m, in \u001B[0;36mmigrate_database\u001B[1;34m(db_path)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m table \u001B[38;5;129;01min\u001B[39;00m tables:\n\u001B[0;32m    112\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m table \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdissolved_oxygen_study_table\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdissolved_oxygen_records\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 113\u001B[0m         \u001B[43mcursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDROP TABLE \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtable\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDropped table \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtable\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    115\u001B[0m conn\u001B[38;5;241m.\u001B[39mcommit()\n",
      "\u001B[1;31mOperationalError\u001B[0m: table sqlite_sequence may not be dropped"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T20:47:09.783663Z",
     "start_time": "2025-02-11T20:47:09.780510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_dissolved_oxygen_records(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create new tables if they don't exist\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS do_testing (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            sample_name TEXT,\n",
    "            sample_id INTEGER,\n",
    "            time TEXT,\n",
    "            dissolved_oxygen REAL,\n",
    "            nanoamperes REAL,\n",
    "            temperature REAL,\n",
    "            FOREIGN KEY(sample_id) REFERENCES phantom_study_metadata(id)\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS do_phantom_imaging (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            sample_name TEXT,\n",
    "            sample_id INTEGER,\n",
    "            time TEXT,\n",
    "            dissolved_oxygen REAL,\n",
    "            nanoamperes REAL,\n",
    "            temperature REAL,\n",
    "            FOREIGN KEY(sample_id) REFERENCES phantom_study_metadata(id)\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    # Split records based on date\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO do_testing (sample_name, sample_id, time, dissolved_oxygen, nanoamperes, temperature)\n",
    "        SELECT sample_name, sample_id, time, dissolved_oxygen, nanoamperes, temperature\n",
    "        FROM dissolved_oxygen_records\n",
    "        WHERE DATE(time) <= '2025-02-06'\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO do_phantom_imaging (sample_name, sample_id, time, dissolved_oxygen, nanoamperes, temperature)\n",
    "        SELECT sample_name, sample_id, time, dissolved_oxygen, nanoamperes, temperature\n",
    "        FROM dissolved_oxygen_records\n",
    "        WHERE DATE(time) = '2025-02-07'\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Records successfully split by date.\")\n"
   ],
   "id": "775691c534993334",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T20:47:38.470944Z",
     "start_time": "2025-02-11T20:47:38.434361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_path = r\"C:\\Users\\jdivers\\PycharmProjects\\df_image_analysis\\databases\\phantoms2_backup.db\"\n",
    "split_dissolved_oxygen_records(db_path)"
   ],
   "id": "634cef1eb171c9aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records successfully split by date.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## MCLUT\n",
    "'1d_mclut_w50000_photons.db' contains simulation parameters and results from a Monte Carlo photon simulator. It should be refactored so each row contains a label for the 'simulation_id' that is a foreign key to a 'master_mclut' database with details of the simulation, 'dimensions'and 'photon_count', (encoded in the current database name). These tables should be migrated to the new master study database.\n",
    "\n",
    "Currently, the database has one table that looks like this: \n",
    "**<name=1d_mclut_w50000_photons.db>**\n",
    "\n",
    "| id | mu_s | mu_a | g   | depth | transmission | reflectance | absorption |\n",
    "|:---|:-----|:-----|:----|:------|:-------------|:------------|:-----------|\n",
    "| 1 | BLOB | BLOB | 0.0 | 0.1   | 0.5          | 0.2         | 0.8        |\n",
    "| 2 | BLOB | BLOB | 0.1 | 0.1   | 0.5          | 0.21        | 0.79       |\n",
    "|...| ...  | ...  | ... | ...   | ...          | ...         | ...        |\n",
    "\n",
    "I'd like to simply convert the BLOB dtypes to floats and add a column to that table with a foreign key that points to a table with simulation details like this:\n",
    "\n",
    "\n",
    "**<name=dissolved_oxygen_records>**\n",
    "\n",
    "| id | photon_count | dimensionality | water_n | water_mu_s | water_mu_a | tissue_n | surroundings_n |\n",
    "|:---|:-------------|:---------------|:--------|:-----------|:-----------|:---------|:---------------|\n",
    "| 1  | 50000 | 1.0            | 1.0 | 0.003 | 0.0 | 1.4 | 1.0            |\n",
    "| ...|             | ...            | ... | ... | ...   | ... | ... | ...            | "
   ],
   "id": "3a81c49e43e4c35e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:20:09.493943Z",
     "start_time": "2025-02-11T21:20:09.489759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mclut_record_update(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS mclut_simulations (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    photon_count INT NOT NULL,\n",
    "    dimensionality INT NOT NULL,\n",
    "    water_n FLOAT NOT NULL,\n",
    "    water_mu_s FLOAT NOT NULL,\n",
    "    water_mu_a FLOAT NOT NULL,\n",
    "    tissue_n FLOAT NOT NULL,\n",
    "    surroundings_n FLOAT NOT NULL\n",
    "    )\"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"PRAGMA foreign_keys=OFF\"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS sim_res_temp (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    mu_s FLOAT NOT NULL,\n",
    "    mu_a FLOAT NOT NULL,\n",
    "    g FLOAT NOT NULL,\n",
    "    depth FLOAT NOT NULL,\n",
    "    transmission FLOAT NOT NULL,\n",
    "    reflectance FLOAT NOT NULL,\n",
    "    absorption FLOAT NOT NULL,\n",
    "    simulation_id INT,\n",
    "    FOREIGN KEY(simulation_id) REFERENCES mclut_simulations(id))\"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "    INSERT INTO sim_res_temp (id, mu_s, mu_a, g, depth, transmission, reflectance, absorption)\n",
    "    SELECT id, mu_s, mu_a, g, depth, transmission, reflectance, absorption FROM simulation_results\n",
    "    \"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"DROP TABLE IF EXISTS simulation_results\"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"ALTER TABLE sim_res_temp RENAME TO simulation_results\"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.execute(\"\"\"PRAGMA foreign_keys=ON\"\"\")\n",
    "    conn.close()"
   ],
   "id": "41e698671d4980da",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:20:10.147953Z",
     "start_time": "2025-02-11T21:20:10.107791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_path = r'C:\\Users\\jdivers\\PycharmProjects\\df_image_analysis\\databases\\1d_mclut_w50000_photons.db'\n",
    "mclut_record_update(db_path)"
   ],
   "id": "1112d552a932b76c",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:51:43.655099Z",
     "start_time": "2025-02-11T21:51:43.649913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_blob_to_float(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS sim_res_temp (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    mu_s FLOAT NOT NULL,\n",
    "    mu_a FLOAT NOT NULL,\n",
    "    g FLOAT NOT NULL,\n",
    "    depth FLOAT NOT NULL,\n",
    "    transmission FLOAT NOT NULL,\n",
    "    reflectance FLOAT NOT NULL,\n",
    "    absorption FLOAT NOT NULL,\n",
    "    simulation_id INT,\n",
    "    FOREIGN KEY(simulation_id) REFERENCES mclut_simulations(id))\"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"SELECT id, mu_s, mu_a, g, depth, transmission, reflectance, absorption FROM simulation_results\"\"\")\n",
    "    data = cursor.fetchall()\n",
    "    new_data = [(d[0],  struct.unpack('q', d[1])[0],  struct.unpack('q', d[2])[0], d[3], d[4], d[5], d[6], d[7]) for d in data]\n",
    " \n",
    "    cursor.executemany(\"\"\"INSERT INTO sim_res_temp (id, mu_s, mu_a, g, depth, transmission, reflectance, absorption)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?)\"\"\", new_data)\n",
    "    \n",
    "    cursor.execute(\"\"\"DROP TABLE IF EXISTS simulation_results\"\"\")\n",
    "    \n",
    "    cursor.execute(\"\"\"ALTER TABLE sim_res_temp RENAME TO simulation_results\"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "    conn.close()"
   ],
   "id": "6906457cf16169e8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:51:44.740155Z",
     "start_time": "2025-02-11T21:51:44.622784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_path = r'C:\\Users\\jdivers\\PycharmProjects\\df_image_analysis\\databases\\1d_mclut_w50000_photons.db'\n",
    "update_blob_to_float(db_path)"
   ],
   "id": "474f4a8d5b247d06",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Combining databases\n",
    "Once we have cleaned and organized those databases/tables, I'd like to migrate all of the altered databases and 'hbo2_hb.db' into the master study database as well. It can simply be moved in as a table. No additional processing should be required."
   ],
   "id": "58b20080ad2f696e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T22:11:00.917737Z",
     "start_time": "2025-02-11T22:11:00.867243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn = sqlite3.connect('hsdfm_data.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"ATTACH DATABASE '1d_mclut_w50000_photons.db' AS mclut_db\"\"\")\n",
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS mclut_simulations AS SELECT * FROM mclut_db.mclut_simulations\"\"\")\n",
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS mclut AS SELECT * FROM mclut_db.simulation_results\"\"\")\n",
    "cursor.execute(\"\"\"UPDATE mclut SET simulation_id = 1\"\"\")\n",
    "conn.commit()\n",
    "cursor.execute(\"\"\"DETACH DATABASE mclut_db\"\"\")\n",
    "cursor.execute(\"\"\"ATTACH DATABASE 'hbo2_hb.db' AS hb\"\"\")\n",
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS hb_spectra AS SELECT * FROM hb.molar_extinction_data\"\"\")\n",
    "conn.commit()\n",
    "cursor.execute(\"\"\"DETACH DATABASE hb\"\"\")\n",
    "cursor.execute(\"\"\"ATTACH DATABASE 'phantoms2_backup.db' as phantoms\"\"\")\n",
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS phantom_imaging AS SELECT * FROM phantoms.do_phantom_imaging\"\"\")\n",
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS do_testing AS SELECT * FROM phantoms.do_testing\"\"\")\n",
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS phantoms AS SELECT * FROM phantoms.phantom_study_metadata\"\"\")\n",
    "conn.commit()\n",
    "cursor.execute(\"\"\"DETACH DATABASE phantoms\"\"\")\n",
    "conn.close()"
   ],
   "id": "74e03e67b63087cd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a4fcb4f7df536109"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
